{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Machine Learning Readability\n",
    "\n",
    "__Source:__ https://www.kaggle.com/learn/machine-learning-explainability\n",
    "\n",
    "The following are techniques to establish how to read results of models and how to figure out the features to get there.\n",
    "\n",
    "## 1. Permutation Importance\n",
    "\n",
    "Permutation Importance is a simple sklearn way of identifying the best features. This is good if the data isn't intuitive or you don't have proper labels on your data - that way, you can work with the highest correlated features and play with them to get even better features.\n",
    "\n",
    "Permutation importances are done __after a model has been fit!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain feature importance via \"eli5\" sklearn library\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "base_features = ['pickup_longitude',\n",
    "                 'pickup_latitude',\n",
    "                 'dropoff_longitude',\n",
    "                 'dropoff_latitude',\n",
    "                 'passenger_count']\n",
    "\n",
    "# fit model first!\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "first_model = RandomForestRegressor(n_estimators=30, \n",
    "                                    random_state=1)\n",
    "first_model.fit(train_X, train_y)\n",
    "\n",
    "# permutation importance requires a second fit...but gotta separately fit the model first\n",
    "\n",
    "perm = PermutationImportance(first_model, random_state=1).fit(val_X, val_y)\n",
    "\n",
    "eli5.show_weights(perm, feature_names = base_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Partial Dependence Plots\n",
    "\n",
    "Feature Importance above shows _what_ variables most affect predictions...but it doesn't show _how_ a feature affects a prediction.\n",
    "\n",
    "That's where __Partial Dependence Plots__ come in. Like Permutations, PD plots are calculated __after__ a model has been fit.\n",
    "\n",
    "__How it Works:__ You alter the value of _one feature_ after a model has been fit and see the change in predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_model = DecisionTreeClassifier(random_state=0, \n",
    "                                    max_depth=5, \n",
    "                                    min_samples_split=5).fit(train_X, train_y)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "# Create the data that we will plot\n",
    "pdp_goals = pdp.pdp_isolate(model=tree_model, dataset=val_X, model_features=feature_names, feature='Goal Scored')\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(pdp_goals, 'Goal Scored')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the PDP Graph: \n",
    "- x axis is the feature values (price, goals scored, etc.)\n",
    "- y axis is the change in prediction from what it would be predicted at the baseline (leftmost of the graph) value. Shaded area is a confidence interval.\n",
    "\n",
    "PDP Graphs only analyze one feature. However, you can change it to account for changes in _two_ features in a quasi-heatmap graph, where the heat is the degree of change. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2 feature PDP graph is similar to regular PDP plot except we use pdp_interact \n",
    "instead of pdp_isolate and pdp_interact_plot instead of pdp_isolate_plot\n",
    "'''\n",
    "features_to_plot = ['Goal Scored', 'Distance Covered (Kms)']\n",
    "inter1  =  pdp.pdp_interact(model=tree_model, dataset=val_X, model_features=feature_names, features=features_to_plot)\n",
    "\n",
    "pdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=features_to_plot, plot_type='contour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SHAP Values\n",
    "\n",
    "__SHAP:__ \"SHapley Additive exPlanations\" breaks down a prediction and shows the impact of _each_ feature. The SHAP values of all features sum up to explain why my prediction was different from the baseline. For example, if the model predicted \"0.7\" and the baseline actual value is 0.5, below the outputted line graph is an explanation of which features pushed the prediction higher and which features contibuted to it being lower. Totalling those feature influences up, you get 0.7.\n",
    "\n",
    "Good examples for looking into SHAP values are:\n",
    "- A model says a bank shouldn't loan someone money, and the bank is legally required to provide a basis for the loan rejection.\n",
    "\n",
    "- A healthcare provider wants to identify the factors that are driving the patient's risk of some disease, so that those factors can be targeted.\n",
    "\n",
    "Example of SHAP value code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "my_model = RandomForestClassifier(random_state=0).fit(train_X, train_y)\n",
    "\n",
    "row_to_show = 5\n",
    "data_for_prediction = val_X.iloc[row_to_show]  \n",
    "# use 1 row of data here. Could use multiple rows if desired\n",
    "\n",
    "data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n",
    "\n",
    "\n",
    "my_model.predict_proba(data_for_prediction_array)\n",
    "\n",
    "########################################################\n",
    "\n",
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "# Also DeepExplainer for Deep Learning models and\n",
    "# KernelExplainer for all other models (although generally slower and offers only an approximation)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = explainer.shap_values(data_for_prediction)\n",
    "# The above variable creates two arrays - feature by feature probability of a negative outcome\n",
    "# and feature by feature probability of a positive outcome\n",
    "\n",
    "# may just use X_test for \"data_for_prediction\"\n",
    "\n",
    "########################################################\n",
    "# An easier way to understand the above SHAP value arrays is to visualize them\n",
    "# Below is the code for that:\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)\n",
    "\n",
    "# can also do\n",
    "shap.summary_plot(shap_values[1], val_X)\n",
    "\n",
    "# NOTE: As stated above, SHAP values has two arrays (probability of outputting 0 and probability of outputting 1)\n",
    "# . We are calling the one for TRUE/1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using Permutation Importance, Partial Dependence Plots, and SHAP Values Together\n",
    "\n",
    "__Permutation Importance__ shows _which_ features are important.\n",
    "__SHAP Values__ show how _all_ features affect the model.\n",
    "__Partial Dependence Plot__ shows how _a specific feature_ affects the model.\n",
    "\n",
    "Combining SHAP values and dependence plots, we get a new kind of plot: __Dependence Contribution Plots.__ These plots use SHAP values as the y axis and the analyzed feature on the x axis. The general trend of the scatter will suggest the correlation (if any) of that feature with the outcome variable. (You can also color the scatter points for analysis of another variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-066faccb553e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Do the below on X_test, ***after*** fitting the model!!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m  \u001b[1;31m# package used to calculate Shap values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Create object that can calculate shap values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "# Contibution Plot example\n",
    "# Do the below on X_test, ***after*** fitting the model!!!\n",
    "\n",
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# make plot.\n",
    "shap.dependence_plot('Ball Possession %', shap_values[1], X, interaction_index=\"Goal Scored\")\n",
    "# HERE - Ball possession = feature analyzed in relation to its SHAP value\n",
    "# Goal scored - the color-coded feature for extra-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KHAN ACADEMY NOTES: Algorithms\n",
    "\n",
    "## Binary Search\n",
    "\n",
    "Imagine trying to find a book in a list of 50 books, ordered numerically from 1 to 50. __Linear Search__ starts at Book \\#1, checks to see if that book is correct, and if not, go onto Book \\#2, and if not correct, then onto Book \\#3, etc.\n",
    "\n",
    "In a linear search, the worst case scenario is if Book \\#50 is the correct book. That's 50 guesses! A basic algorithm in computers is to instead use \n",
    "\n",
    "__Binary Search.__ Here, binary search checks Book #\\25, checks if the actual book is higher or lower. If higher, it rejects Books 1 to 24, and it's second guess would be Book \\# 38 - halfway between books 26 and 50. The Binary Search algorithm repeats the high/low check until it finds the correct book.\n",
    "\n",
    "For a linear search, the maximum number of guesses for a list of n books is n. For a binary search, the maximum number of guesses is log<sub>2</sub>(n), rounded up. As you can see, this is _exponentially_ more performant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Asymptotic Notation - Determining the Efficiency (Rate) of an Algorithm\n",
    "\n",
    "Measuring _how long_ exponentially performant algorithms such as Binary Search take is defined by asymptotic notation. There are three forms: Big Theta, Big-O, and Big-Omega notations.\n",
    "\n",
    "### Big Theta Notation\n",
    "\n",
    "Used for functions involving a _constant_ runtime. for k1 x n and k2 x n, where (k1 x n) < runtime function < (k2 x n), the runtime rate would be approximately somewhere _in_ between k2 x n and k1 x n _after a sufficiently large n_; before this sufficiently large n, runtime cannot be adequately determined. If the above inequality holds true, we say \"the running time is Theta(n).\" In laymen's terms, this says \"if the running time of the function f(n) is Theta(g(n)), then f(n) grows asymptotically _at the same rate_ as g(n).\"\n",
    "\n",
    "### Big-O Notation\n",
    "\n",
    "Big-Theta designates a runtime between an upper and lower bound functions, but we don't know exactly where in between those functions the runtime function is in. Big-O notation expressly identifies __only the upper bound function__ and says that \"runtime is lower than (or \"at most\") O(n).\" (pronounced \"Big-O of f(n)\" or just \"O of f(n)\").\n",
    "\n",
    "Although it gives less information than Big-Theta, it is more accurate that works in all cases for a given function. In laymen's terms, \"If f(n)'s runtime is O(g(n)), then f(n) grows asymptotically _no faster than_ g(n).\"\n",
    "\n",
    "__An example explaining the difference:__\n",
    "for binary search algorithm f(n), if the runtime rate is k * log(n) + c, where k and c are constants, \n",
    "\n",
    "We say that f(n) is Theta(log(n)) (same rate as runtime rate)\n",
    "\n",
    "We say that f(n) is O(log(n)), O(n), O(n^2), O(n^3), and O(2^n) (as the runtime rate is \"no faster than the rate of Big-O\")\n",
    "\n",
    "### Big-Omega Notation\n",
    "\n",
    "If Big-O is an upper bound, Big-Theta is an upper _and_lower bound_, then Big-Omega must be the rate \"_at least_ the rate of the runtime of the function\" (i.e., asymptotic lower bounds).\n",
    "\n",
    "#### What's the deal with the above?\n",
    "\n",
    "It gives programmers knowledge of the worst-case scenario of runtime (Big-Omega) or best-case scenario of runtime (Big-O). For example, Omega(1) means that the function works _at least_ on pace with constant time - it could very well program faster (such as polynomially (n^2 or 3n^4) or exponentially (3.5^n or 2^(2n)))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sorting - Selection Sort\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
