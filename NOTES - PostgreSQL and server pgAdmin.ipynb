{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL NOTES\n",
    "\n",
    "These are notes on SQL syntax. While these notes focus on syntax with PostgreSQL, the idea of the querying syntax may apply to other SQL languages. For example, MySQL is almost identical to PostgreSQL in terms of syntax, with the exception of a couple of minor points (of course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Datasets to Work with\n",
    "\n",
    "As an initial matter, we can use [this SQL IDE](https://www.db-fiddle.com/) for playing around with SQL datasets.\n",
    "\n",
    "[Sample Dataset 1: Novels](https://raw.githubusercontent.com/ephs08kmp/sql_workshop_schema/master/sql_example.txt) <br>\n",
    "[Sample Dataset 2: Train Stations](https://raw.githubusercontent.com/ephs08kmp/sql_workshop_schema/master/sql_workshop.txt)\n",
    "***\n",
    "### Good Practice\n",
    "\n",
    "One cannot say that s/he is \"proficient\" at PostgreSQL without [completing these exercises in full!](https://pgexercises.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING DATA INTO PostgreSQL - HOW TO!!!!!\n",
    "\n",
    "Three main ways:\n",
    "1. Load data into a database from a _.sql file_.\n",
    "    - The one that will be referred to in these notes is the open-source __PgAdmin4__\n",
    "2. Load data into a database from a different tabular file, such as a _.csv file_.\n",
    "3. Create the table parameters manually within the database.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A. NORMAL LOADING FROM .sql FILE\n",
    "\n",
    "_How to do in __PgAdmin__:_\n",
    "\n",
    "1. (Right click on) Database - Create -> Database\n",
    "2. (Right click on) (Newly Created Database) - Query Tool...\n",
    "3. On the query tool toolbar, open file\n",
    "\n",
    "### What is a 'Database File' and What is a 'Query Tool'?\n",
    "\n",
    "- __Database File__ = folder containing all relevant \\*\\*\\*\\*\\*\\*.sql\\*\\*\\*\\*\\*\\* files\n",
    "<br>\n",
    "- __Query Tool__ = A tool used to 'query' information from files - the main thing of SQL (see below section)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. IMPORT DATA FROM .csv FILE - HOW-TO!\n",
    "\n",
    "__Two Main ways to import data from non-.sql files: via (a) the Query Tool or via (b) the database program itself.__ <br><br>\n",
    "\n",
    "a. __Create Table manually under Query Tool:__\n",
    "<br><br>\n",
    "   - `CREATE TABLE` (follow Create Table syntax above, i.e., listing column name and type)\n",
    "   - Populating the newly created table via the query tool requires:\n",
    "      ```SQL\n",
    "      COPY table_name(column_name1, column_name2, column_name3...)\n",
    "      FROM 'C:\\Users\\jafon\\Documents\\PythonMaterials\\Data\\AirBnB_Listings\\listings.csv' \n",
    "      WITH DELIMITER ',' csv HEADER;\n",
    "      ```\n",
    "    \n",
    "b. __Import Data into newly created table:__\n",
    "<br><br>\n",
    "(Under Browser): Database - Schemas - public - Tables (right click) -> Create -> Table\n",
    " - Name the Table (something different than the create Table under the query)\n",
    " - Under Columns - populate the column names by clicking on the dropdown, selecting the table you just created via the query (or I guess you could manually write out the columns here - You can skip step 1 if you do this)\n",
    " - Click save and create the table \n",
    " - Access this newly table under the browser -> (right click) -> Import/Export -> Choose Impport\n",
    " - Select location of dataset file\n",
    " - Header YES or ON, DELIMITER ','\n",
    " - Save and Import\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "### POTENTIAL ERRORS TO LOADING DATA (and their solutions):\n",
    "\n",
    "- ___\"There is no such file or directory\"___ or ___\"permission denied\":___\n",
    "     - There is a permission error from Windows blocking pgAdmin from accessing the file folder\n",
    "     - Right-click on the folder that contains the desired file -> Properties -> Change user permissions\n",
    "        <br><br>    \n",
    "- ___\"extra data after last expected column\":___\n",
    "     - The number of columns being imported does not match up with the number of columns listed in the `COPY table_name(...)` query<br><br>\n",
    "    - This addresses an important point of data loading for PostgreSQL, __IMPORTANT!!!!:__ You MUST import ***ALL*** of the columns from the csv; you cannot pick and choose!\n",
    "    \n",
    "      - There are two ways to fix this: <br>\n",
    "      1. Deleting unnecessary columns in the original csv dataset - saving a new copy and loading from there\n",
    "          - This is called \"preprocessing\" the data - and it is the easiest way\n",
    "      2. Import ALL columns FIRST from csv, THEN modify the table\n",
    "          - a. \n",
    "          ```SQL \n",
    "          ALTER TABLE table_Name DROP COLUMN column5\n",
    "          ALTER TABLE table_Name DROP COLUMN column2 (etc.)\n",
    "          ```\n",
    "          - b. This may be too process-heavy/cumbersome for super large datasets\n",
    "              - You can skip this by creating and intermediary table AND THEN picking and choosing from there: <br>\n",
    "              ```SQL\n",
    "              CREATE temporary table t (x1 integer, ... , x10 text)\n",
    "              -- Copy from the file into it:\n",
    "              COPY t (x1, ... , x10)\n",
    "              FROM '/path/to/my_file'\n",
    "              WITH  (format csv)\n",
    "              \n",
    "              INSERT INTO my_table (x2, x5, x7, x10)\n",
    "              SELECT x2, x5, x7, x10\n",
    "              FROM t\n",
    "              \n",
    "              DROP TABLE t;\n",
    "              ```   \n",
    "__NOTE!!!: This is a good method for re-ordering columns too!__\n",
    "<br><br>\n",
    "Overall,\n",
    "<br><br>\n",
    "The failure to easily choose column order and modify tables is a severe limitation of postgreSQL/pgAdmin. Other sql databse programs (e.g., MySQL database(s)) allow you to pick and choose columns normally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. TABLE CREATION - THE MAIN WAY TO DO BUSINESS!\n",
    "\n",
    "Instead of importing data from an existing table, we can alternatively create own table!\n",
    "\n",
    "```SQL\n",
    "CREATE TABLE table_name (\n",
    "    some_column_name TYPE column_constraint,\n",
    "    column_2_name TYPE, \n",
    "    column_3_name TYPE column constraint\n",
    "    );\n",
    "```\n",
    "\n",
    "### What is TYPE?\n",
    "\n",
    "__TYPE__ is the defined data type of the values within that column - yes, all values within the same column MUST be the same data type (unless you define it as \"VarChar\" (variable characters), which is unadvised and should only be used (1) as a placeholder or (2) if the data type isn't important for that column and want to avoid errors during importing). \n",
    "<br><br>\n",
    "Examples of type are: \n",
    "- TEXT \n",
    "- INTEGER \n",
    "- NUMERIC or \n",
    "- VARCHAR(100) (number of max characters, regardless of type) or DATE. Check the internet for more data types!\n",
    "\n",
    "#### Two Notes on VARCHAR(x)...\n",
    "\n",
    "1. VARCHAR is a good placeholder, but unless you plan on _not_ performing any querying operations on that column that require a certain data type (numerical operations, DATE-time operations, etc.), you should go with a more specific datatype\n",
    "    - One good reason to use VARCHAR is to avoid type-specific errors during importation of the data...which will LIKELY happen for data that is not 100% clean (which is always the case)!!!!!\n",
    "<br>\n",
    "\n",
    "2. SQL cannot handle arrays - it mimics the conceptual formatting of csv data (which is not in arrays). _Sometimes_, VARCHAR data may be interpreted as an array for SQL, which will invariably trigger an error! If this happens, choose a different data format, or preprocess the data to steer away from arrays.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are Constraints?\n",
    "\n",
    "A `column_constraint` can be:<br><br>\n",
    "1. A __boolean__ (constrain by \"true\", \"false\", or \"null\" values). Two examples:\n",
    "    - `price numeric CHECK (price > 0)` ---- (for 'checking' positive prices)\n",
    "    - (Can be multiple booleans, with a final \"CHECK\" not corresponding to any one particular column):<br>\n",
    "\n",
    "```SQL\n",
    "price numeric CHECK (price > 0), \n",
    "discounted_price numeric CHECK (discounted_price > 0), \n",
    "CHECK (price > discounted_price);\n",
    "```\n",
    "\n",
    "***    \n",
    "2. __NOT NULL__ (constrain by only non-null's)\n",
    "    - Example:\n",
    "```SQL\n",
    "name text NOT NULL,\n",
    "price numeric NOT NULL CHECK (price > 0) \n",
    "```\n",
    "<br>\n",
    "- The second example can also be defined in a query, such as:\n",
    "\n",
    "```SQL\n",
    "select * from calendar\n",
    "where price is not null\n",
    "order by 4 DESC;\n",
    "```\n",
    "***\n",
    "3. __UNIQUE__ (constrain by no duplicate values within that column)\n",
    "    - Example: `product_no integer UNIQUE`\n",
    "\n",
    "    - Can also combine uniques, such as making sure there are no _combinations_ of \"a _and_ c values\". This means that for row values for columns a and c: <br>\n",
    "    12 24 (1) <br>\n",
    "    12 12 (2) <br>\n",
    "    12 24 (3) <br>\n",
    "    22 24 (4) <br>\n",
    "    Row (3) would be taken out, and all other rows would be kept.\n",
    "<br>\n",
    "***\n",
    "4. __PRIMARY KEY__ (equivalent to UNIQUE + NOT NULL on a column)\n",
    "    - can also do PRIMARY KEY (a, c) too\n",
    "<br><br>\n",
    "Check the internet for the other constraints that can be done!\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******NOTE!: Once a table is created, the order of the columns CANNOT be modified.\n",
    "What you can do is rename all of the columns before populating with data \n",
    "by right clicking on each column and modifying until you are satisfied with the order\n",
    "\n",
    "###\n",
    "                        \n",
    "**********************How to alter columns\n",
    "altering a table is simple - just do an ALTER TABLE call\n",
    "ALTER TABLE table_name\n",
    "ALTER COLUMN column_name TYPE new_desiredcolumn type\n",
    "\n",
    "if that doesn't work, do this\n",
    "ALTER TABLE table_name\n",
    "ALTER COLUMN column_name TYPE new_desiredcolumn type\n",
    "USING column_name::new_desired column type\n",
    "\n",
    "example\n",
    "ALTER TABLE calendar\n",
    "ALTER COLUMN price TYPE MONEY NOT NULL\n",
    "USING price::MONEY\n",
    "\n",
    "\n",
    "# FINAL NOTE***************\n",
    "double dash (--) is used for comments in PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN QUERY TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "1. SELECT _____ FROM _____;\n",
    "\n",
    "# Select often the first thing to do, unless doing FROM (thing), SELECT...\n",
    "# first space is what you want to look at, i.e., Column names\n",
    "# Use SELECT * if you want to look at whole table\n",
    "# second space is name of SQL file you want to look at\n",
    "#semicolon at end doesn't do anything - just conventional\n",
    "# example:\n",
    "     SELECT temperature, clouds_and_sun FROM weather;\n",
    "    \n",
    "# while both can be syntactically accepted, \n",
    "# it is convention to do multiple rows\n",
    "\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    stations;\n",
    "    \n",
    "# Can also change column names\n",
    "\n",
    "SELECT\n",
    "    temperature temp\n",
    "FROM\n",
    "    weather;\n",
    "# can also do temperature AS temp (but typing the word AS is unnecessary)\n",
    "\n",
    "2. WHERE\n",
    "# purpose = can filter upon boolean conditions\n",
    "\n",
    "# a.  use BETWEEN for ranges:\n",
    "a BETWEEN x AND y # equivalent to a >= x AND a <= y\n",
    "a NOT BETWEEN x AND y # equivalent to a < x OR a > y\n",
    "\n",
    "# b.  use LIKE for matching strings:\n",
    "\"abc\" LIKE \"abc\"    true\n",
    "'abc' LIKE 'a%'     true # % = matches any preceding or following sequence of\n",
    "                         # 0 or more characters\n",
    "'abc' LIKE '_b_'    true # _ = matches any single character\n",
    "'abc' LIKE 'c'      false\n",
    "# b. use SIMILAR TO for string matching via regular expressions\n",
    "# regex in a different noteset...\n",
    "\n",
    "3. ORDER BY\n",
    "# purpose = applies order of values\n",
    "\n",
    "4. LIMIT\n",
    "# purpose = returns set maximum number of values, e.g., \"three longest trips\"\n",
    "# good to do generally if your computer is having a difficult time loading a \n",
    "# dataset, e.g., use LIMIT 10000;\n",
    "SELECT\n",
    "    trip_id,\n",
    "    start_date,\n",
    "    duration\n",
    "FROM\n",
    "    trips\n",
    "WHERE\n",
    "    bike_id = 27,\n",
    "    zip_code = 94107 AND\n",
    "    subscriber_type LIKE \"Customer\" #always double quotes in SQL\n",
    "ORDER BY duration DESC,\n",
    "start_date ASC # can order columns sequentially, i.e., if the duration column has duplicates, go to start_date to sort\n",
    "LIMIT 3;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reference - not a note!\n",
    "COPY listings(name, host_name, neighbourhood, latitude, longitude, room_type, price, \n",
    "reviews_per_month, availability_365, lastreview, host_count, id, hostid, \n",
    "numberofreviews, minimumnights)\n",
    "from 'C:\\Users\\jafon\\Documents\\PythonMaterials\\Data\\AirBnB_Listings\\listings.csv' with delimiter ',' csv header; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGGREGATING AND GROUPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGGREGATING means can be done via similar NumPy methods\n",
    "SELECT\n",
    "    city, \n",
    "    AVG(lat) AS latitude,\n",
    "    AVG(long) AS longitude,\n",
    "    MAX(time),\n",
    "    COUNT(*) AS station_count\n",
    "FROM\n",
    "    stations;\n",
    "    \n",
    "#GROUPING gets rids of duplicates, similar to UNIQUE in creating a table\n",
    "SELECT\n",
    "    city, \n",
    "    lat AS latitude,\n",
    "    long AS longitude,\n",
    "    MAX(time),\n",
    "    COUNT(*) AS station_count\n",
    "FROM\n",
    "    stations\n",
    "GROUP BY 1, 2, 3; # grouping by city, latitude, and longitude. \n",
    "# Can write out names of grouping columns too, but numbers are easier\n",
    "# NOTE***: Cannot group aggregated columns (as there is now only a \n",
    "# single value for that column)\n",
    "# NOTE***: THEREFORE, must group ALL OTHER columns!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOINS join MULTIPLE TABLES together\n",
    "# In this instance, MUST identify the table from which a specific column comes from\n",
    "SELECT\n",
    "    trips.trip_id,\n",
    "    trips.start_station,\n",
    "    stations.lat,\n",
    "    stations.long\n",
    "FROM\n",
    "    trips \n",
    "JOIN\n",
    "    stations\n",
    "ON\n",
    "    trips.start_station = stations.name; # where to do the join\n",
    "# note that the values of the two ONs ***MUST BE THE SAME TO DO THE JOIN***\n",
    "# (the column names need not be the same - just the values of those columns)\n",
    "# See example in CTEs below on how to get around this (do multiple joins across tables)\n",
    "    \n",
    "# Can also use \"aliases\" to shorten table names. The above is the same as:\n",
    "SELECT\n",
    "    t.trip_id,\n",
    "    t.start_station,\n",
    "    s.lat,\n",
    "    s.long\n",
    "FROM\n",
    "    trips t\n",
    "JOIN\n",
    "    stations s\n",
    "ON\n",
    "    t.start_station = s.name;\n",
    "    \n",
    "# TYPES OF JOINS\n",
    "1. INNER JOIN  - returns only matching columns, dropping everything else \n",
    "# SQL default^^^, i.e., same as JOIN\n",
    "2. OUTER JOIN - returns everything, leaving non-matches as null values\n",
    "# not recommended, as may choke up computer when viewing large databases\n",
    "3. LEFT JOIN - returns everything on left table, leaves non-matches on \n",
    "right table as null values\n",
    "4. RIGHT JOIN - returns everything on right table, leaves non-matches on \n",
    "left table as null values\n",
    "# more difficult to read since we read left to right - \n",
    "# better to flip around the tables in the query and do a left join instead\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMMON TABLE EXPRESSIONS (CTEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTE is joining a table on a previously processed query,\n",
    "# (as opposed to joining two tables)\n",
    "\n",
    "# Important to do because aggregation functions happen AFTER joins occur\n",
    "\n",
    "CTE = WITH \n",
    "    Name of CTE to refer to later\n",
    "AS (\n",
    "    first query\n",
    ")\n",
    "SELECT\n",
    "    second query\n",
    ");\n",
    "\n",
    "# EXAMPLE to break down:\n",
    "WITH\n",
    "    locations\n",
    "AS (\n",
    "    -- A simple query to get the averages of lat and long on a city level.\n",
    "    SELECT\n",
    "        city,\n",
    "        AVG(lat) lat,\n",
    "        AVG(long) long\n",
    "    FROM\n",
    "        stations\n",
    "    GROUP BY 1\n",
    ")\n",
    "\n",
    "-- Joining the locations table we created with the trips table to count trips.\n",
    "SELECT\n",
    "    l.city,\n",
    "    l.lat,\n",
    "    l.long,\n",
    "    COUNT(*)\n",
    "FROM\n",
    "    locations l\n",
    "\n",
    "-- We need an intermediate join to go from locations to stations \n",
    "-- because the trips table does not have a \"city\" column.\n",
    "JOIN\n",
    "    stations s\n",
    "ON\n",
    "    l.city = s.city\n",
    "JOIN\n",
    "    trips t\n",
    "ON\n",
    "    t.start_station = s.name\n",
    "GROUP BY 1,2,3;\n",
    "\n",
    "# BREAKDOWN OF EXAMPLE:\n",
    "'''\n",
    "Under *locations*, after finding the averages of lat and long coordinates\n",
    "for the stations of every city,\n",
    "I want to join those values onto trips table.\n",
    "HOWEVER, because trips table does not have a city name column,\n",
    "I must join locations.city onto stations.city,\n",
    "THEN DO A SECOND JOIN of trips.start_station onto stations.name.\n",
    "\n",
    "Then, due to an inner join, the cities will be grouped with the averages of \n",
    "the coordinates, i.e., averages of lat, long, and count of number of trips\n",
    "per city will be outputted.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE WHEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to WHERE - Allows for manipulation of values within a NEW column\n",
    "CASE WHEN _condition_ THEN _value1_ ELSE _value2_ END AS _new_column_name_\n",
    "\n",
    "# example:\n",
    "SELECT\n",
    "    (CASE WHEN dockcount > 20 THEN 'large' ELSE 'small' END) station_size,\n",
    "    COUNT(*) as station_count\n",
    "FROM \n",
    "    stations\n",
    "GROUP BY 1;\n",
    "'''\n",
    "station_size is a new column, yielding *large* or *small* values based on\n",
    "the dockcount, and the query is grouped by large and small.\n",
    "'''\n",
    "# Can do multiple conditions too:\n",
    "SELECT player_name,\n",
    "       weight,\n",
    "       CASE WHEN weight > 250 THEN 'over 250'\n",
    "            WHEN weight > 200 THEN '201-250'\n",
    "            WHEN weight > 175 THEN '176-200'\n",
    "            ELSE '175 or under' END AS weight_group\n",
    "FROM benn.college_football_players\n",
    "# don't need to do BETWEENs since the query is analyzed top-down!\n",
    "# May still want to do that for clarity purposes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for project\n",
    "\n",
    "CREATE TABLE listings (\n",
    "    id BIGINT,\n",
    "    name TEXT,\n",
    "    host_id BIGINT,\n",
    "    host_name TEXT,\n",
    "    neighbourhood_group TEXT,\n",
    "    neighbourhood TEXT,\n",
    "    latitude TEXT,\n",
    "    longitude TEXT,\n",
    "    room_type TEXT,\n",
    "    price REAL,\n",
    "    minimum_nights INTEGER,\n",
    "    number_of_reviews INTEGER,\n",
    "    last_review DATE,\n",
    "    reviews_per_month REAl,\n",
    "    calculated_host_listings_count INTEGER,\n",
    "    availability_365 TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE calendar (\n",
    "\tlisting_id BIGINT,\n",
    "\tcalender_date DATE,\n",
    "\tavailable CHAR,\n",
    "\tprice TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE reviews (\n",
    "\tlisting_id BIGINT,\n",
    "\tid BIGINT,\n",
    "\treview_date DATE,\n",
    "\treviewer_id BIGINT,\n",
    "\treviewer_name TEXT,\n",
    "\tcomments TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE listingstest (\n",
    "    id VARCHAR(100),\n",
    "    name VARCHAR(100),\n",
    "    host_id VARCHAR(100),\n",
    "    host_name VARCHAR(100),\n",
    "    neighbourhood VARCHAR(100),\n",
    "    latitude VARCHAR(100),\n",
    "    longitude VARCHAR(100),\n",
    "    room_type VARCHAR(100),\n",
    "    price VARCHAR(100),\n",
    "    minimum_nights VARCHAR(100),\n",
    "\tavailability_365 VARCHAR(100),\n",
    "    number_of_reviews VARCHAR(100),\n",
    "    last_review VARCHAR(100),\n",
    "    calculated_host_listings_count VARCHAR(100),\n",
    "\treviews_per_month VARCHAR(100)\n",
    "\t);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for thinkful project:\n",
    "\n",
    "1. What is the most expensive listing? What else can you tell me about the listing?\n",
    "\n",
    "select * from listingstest\n",
    "order by price DESC\n",
    "limit 5\n",
    "\n",
    "ANSWER: The most expensive listing in San Francisco is priced at $9,999 per night. Called a \"Test Apartment\", it is an entire\n",
    "apartment  in the Russian Hill neighborhood. It requires a 30-day minimum stay and is available about half the year. According to the number of reviews (zero), no one has taken advantage of this listing.\n",
    "\n",
    "2. What neighborhoods seem to be the most popular?\n",
    "\n",
    "select\n",
    "neighbourhood,\n",
    "avg(number_of_reviews) as numrev,\n",
    "avg(reviews_per_month) as revrate \n",
    "from listingstest\n",
    "where reviews_per_month is not null\n",
    "group by neighbourhood\n",
    "order by 3 desc;\n",
    "\n",
    "ANSWER: The 10 most popular neighborhoods, in order from most popular, are: Presidio, Visitacion Valley, Outer Sunset, Parkside, Outer Richmond, Diamond Heights, Bayview, Ocean View, Excelsior, and Crocker Amazon. Because there was no transactional metric for usage and therefore popularity, popularity was instead determined by the highest average of reviews submitted per month.\n",
    "\n",
    " 3. What time of year is the cheapest time to go to your city? What about the busiest?\n",
    "\n",
    "ANSWER 3a:\n",
    "\n",
    "select calender_date, avg(price) as avgprice \n",
    "from calendar\n",
    "group by 1\n",
    "order by 2 asc\n",
    "limit 50;\n",
    "\n",
    "ANSWER 3a: Out of the top 50 hits for the dataset time period of Dec. 2018 to Dec. 2019, \n",
    "all but 6 hits were in March and April. 5 of the remaining six were in december and january (the last one being in May)\n",
    "\n",
    "ANSWER 3b: \n",
    "\n",
    "SELECT \n",
    "DATE_TRUNC('month', calender_date) m,\n",
    "--DATE_TRUNC is a great method for compiling timestamp type columns by desired field\n",
    "--(in this case, by month)\n",
    "COUNT(listing_id) AS count,\n",
    "-- ^ representing the total count for that particular month\n",
    "SUM(CASE WHEN available = 't' THEN 1 ELSE 0 END) AS tsum,\n",
    "-- ^ representing the total occupied, or \"taken\", count for that particular month\n",
    "SUM(CASE WHEN available = 'f' THEN 1 ELSE 0 END) AS fsum,\n",
    "-- ^ representing the total available, or \"free\", count for that particular month\n",
    "(SUM(CASE WHEN available = 't' THEN 1 ELSE 0 END) * 100.0 / count(listing_id)) AS tratio\n",
    "-- Yes, you can perform arithmetic operations in PostgreSQL\n",
    "-- Make sure, however, that you write out the ENTIRE operation;\n",
    "-- You ***CANNOT*** use newly created columns as part of the operation\n",
    "-- Also, for percentages, use \"100.0\" instead of \"100\" - 100 rounds to an integer while \n",
    "-- float gives you the decimals\n",
    "from calendar\n",
    "GROUP BY m\n",
    "-- As a reminder, when grouping, ALWAYS make sure you are grouping by ALL\n",
    "-- non-aggregated columns that are called.\n",
    "ORDER BY tratio desc;\n",
    "\n",
    "ANSWER 3b: I use a column \"tratio\" to help me determine on a ratio basis what the busiest time of the year is. According to that column, the busiest times of the year is the month of February. The next most busiest months are March, April, May, and January, in that order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE calendar (\n",
    "\tlisting_id BIGINT,\n",
    "\tcalender_date DATE,\n",
    "\tavailable CHAR,\n",
    "\tprice REAL\n",
    ");\n",
    "\n",
    "CREATE TABLE reviews (\n",
    "\tlisting_id BIGINT,\n",
    "\tid BIGINT,\n",
    "\treview_date DATE,\n",
    "\treviewer_id BIGINT,\n",
    "\treviewer_name TEXT,\n",
    "\tcomments TEXT\n",
    ");\n",
    "\n",
    "-- Note: the type values for listings that were recommended by Thinkful caused errors for me\n",
    "-- while varying character is not what I was looking for, \n",
    "-- it was the only thing that helped me move forward with this assignment\n",
    "\n",
    "CREATE TABLE listingstest (\n",
    "    id VARCHAR(100),\n",
    "    name VARCHAR(100),\n",
    "    host_id VARCHAR(100),\n",
    "    host_name VARCHAR(100),\n",
    "    neighbourhood VARCHAR(100),\n",
    "    latitude VARCHAR(100),\n",
    "    longitude VARCHAR(100),\n",
    "    room_type VARCHAR(100),\n",
    "    price MONEY,\n",
    "    minimum_nights VARCHAR(100),\n",
    "\tavailability_365 VARCHAR(100),\n",
    "    number_of_reviews VARCHAR(100),\n",
    "    last_review VARCHAR(100),\n",
    "    calculated_host_listings_count VARCHAR(100),\n",
    "\treviews_per_month VARCHAR(100)\n",
    "\t);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
