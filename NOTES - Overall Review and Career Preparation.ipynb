{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For a Final Review\n",
    "\n",
    "Use [this cheatsheet!](https://ml-cheatsheet.readthedocs.io/en/latest/index.html) Hopefully it will be completed by the time you need it.\n",
    "\n",
    "Also for some motivation on the job hunt, read these stories:\n",
    " - [Farewell App Academy, Part I](https://haseebq.com/farewell-app-academy-hello-airbnb-part-i/)\n",
    " - [Farewell App Academy, Part II](https://haseebq.com/farewell-app-academy-hello-airbnb-part-ii/)\n",
    " - [Ten Rules for Negotiating a Job Offer](https://haseebq.com/my-ten-rules-for-negotiating-a-job-offer/)\n",
    " - [Mastering the Data Science Interview](https://towardsdatascience.com/mastering-the-data-science-interview-15f9c0a558a7)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the Best Way to Pre-Process Your Data????\n",
    "\n",
    "_Normalizer()_ scales the entire row to have normal area of 1. This means _every datapoint_ is separately scaled.\n",
    "\n",
    "_StandardScaler()_ scales column-wise. This means that _every feature_ is scaled to unit variance.\n",
    "\n",
    "[A good way to identify different types of preprocessing scalers](http://benalexkeen.com/feature-scaling-with-scikit-learn/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An open source CS curriculum:\n",
    "https://github.com/ForrestKnight/open-source-cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Flashcards](https://github.com/study-groups/ds-study-group/tree/master/flashcards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[quiz](https://stattrek.com/statistics/dictionary.aspx?definition=z_score) <br>\n",
    "[huge compendium of info](https://chrisalbon.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Point of Terminology\n",
    "\n",
    " - __Parameter__ = modifier in model (e.g.: TfidfVectorizer(Normalize=False))\n",
    " - __Argument__ = variable in function (e.g.: def func_call_add(x, y))\n",
    " - __Method__ = function as part of larger algorithm (dataframe or model, e.g.: df.column2.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Some Interview Resources\n",
    "\n",
    "__Tips:__ \n",
    "- Ask questions: If a question is a good candidate to use a recursive function (a function that calls itself), nonetheless ask the interviewer if that is a path that you should go down. Even if it performs better than an iterative function (non-recursive), the interviewer may still want you to use an iterative function.\n",
    "- Being able to \"code\" something is baseline. Likely, interviewers will want you to code with performance optimization in mind.\n",
    "\n",
    "A TOTAL CAREER ADVICE HELP: https://docs.google.com/document/d/129oEEoTwIfJwrFRl9P3Aa_t7VoKChThhwOc2Jz0fPRM/edit\n",
    "\n",
    "and https://drive.google.com/open?id=1eB1u_L5AYU5cVEc8fE0Ku9vRMS7HDLDi7cwF9fv6anw\n",
    "\n",
    "~80% of interview questions will be found here (it takes time to formulate these questions, so major companies just recycle them).\n",
    "\n",
    "Do it as a real practice test, i.e., don't give yourself too much time! (allot 30-45 min).\n",
    "\n",
    "http://courses.csail.mit.edu/iap/interview/Hacking_a_Google_Interview_Handout_1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-aa812b7d1f7c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-aa812b7d1f7c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.interviewbit.com/courses/programming/\n",
    "    \n",
    "    Good dataset site:\n",
    "        https://github.com/Thinkful-Ed/data-201-resources/blob/master/data-sources.md   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "https://www.springboard.com/blog/data-science-interview-questions/\n",
    "\n",
    "https://medium.com/swlh/how-to-answer-data-science-interview-coding-questions-b5e6b2335c7e\n",
    "\n",
    "https://www.edureka.co/blog/interview-questions/data-science-interview-questions/\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/05/questions-python-for-data-science/\n",
    "\n",
    "https://academy.vertabelo.com/blog/15-python-interview-questions-for-data-science-jobs/\n",
    "\n",
    "https://towardsdatascience.com/notes-and-technical-questions-from-interviewing-as-a-data-scientist-in-2018-20e7e3ee4ab3\n",
    "\n",
    "https://www.udacity.com/course/data-science-interview-prep--ud944\n",
    "\n",
    "https://static1.squarespace.com/static/54bf3241e4b0f0d81bf7ff36/t/55e9494fe4b011aed10e48e5/1441352015658/probability_cheatsheet.pdf\n",
    "\n",
    "https://365datascience.com/wp-content/uploads/2019/02/Interview_FAQ_365datascience.pdf\n",
    "\n",
    "https://www.simplilearn.com/data-science-interview-questions-article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **New** Skills to Learn\n",
    "\n",
    "Does not account for importance of review of already learned skills...\n",
    "\n",
    "__In order of priority:__\n",
    "\n",
    "1. __Big Data__\n",
    "    - \"Distributed Systems\"\n",
    "    - Spark\n",
    "    - Hadoop\n",
    "    - (Learning Hive optional)\n",
    "    <br><br>\n",
    "2. __Visualization Tools__\n",
    "    - Tableau\n",
    "    - (PowerBI and Qlik optional)\n",
    "<br><br>\n",
    "3. __Creating a Web Scraper__\n",
    " - Scrapy\n",
    " - Beautiful Soup\n",
    "<br><br>\n",
    "4. __Linux Command Line__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Comcast Skills\n",
    "\n",
    "## Full Job Description\n",
    "\n",
    "\n",
    "### 1. Basic Information\n",
    "- __Company__: Comcast\n",
    "- __Team__: Next Generation Access Networks (\"NGAN\")\n",
    "- __Position__: Data Analyst/ Data Scientist\n",
    "- __Duration__: Funded through 2020 - potential to go perm or extend through 2021\n",
    "- __Interview Process__: Filtered AI assessment, phone interview then Onsite interview\n",
    "\n",
    "\n",
    "### 2. Top Three Skills Desired\n",
    "\n",
    "1. __Data Analysis/Data Wrangling__: Candidates must have experience manipulating data using SQL -- specifically filtering duplicated data, ranking data and aggregating data.\n",
    "\n",
    "\n",
    "2. __Experience using R or Python__: Candidates must have experience doing data analysis with R or Python -- specifically building data science models with these technologies (can be academic experience).\n",
    "\n",
    "\n",
    "3. __Data Visualization__: Candidates must have experience working with data visualization -- this group using Grafana and Tableau but they are open to other data visualization tool experience. \n",
    "\n",
    "### 3. Nice to Haves\n",
    " \n",
    "__This manager is very passionate about education. Any candidate with a Master’s Degree in BI or Data Analytics is going to be a preference for them! Communication skills will be very important as well -- specifically, being able to communicate and work with multiple managers and learn technologies quickly.__\n",
    " \n",
    "\n",
    "### 4. About the Group and Project\n",
    "\n",
    "- This group is responsible for the Next Generation Access Networks for Comcast and the data science and engineering behind the platform.\n",
    "\n",
    "\n",
    "- This tool is the next generation Comcast-wide workflow orchestration tool for Construction & Engineering teams to manage and track progress of all construction job types – Providing visibility into status of milestones, accurate cost of each project, the data to build forecasts, and the ability to roll up those metrics into a national reporting view.\n",
    "\n",
    "\n",
    "- Work is related to the Access Network (cables and related utility infrastructure). Comcast Broadband service has over 50 million customers in U.S and they are responsible for analyzing customer data.\n",
    "\n",
    "\n",
    "- They are responsible for “The last mile”, i.e., collecting data from different sources and then ingesting that into their data lake\n",
    "\n",
    "\n",
    "- The high level functionality of the tool includes tracking and managing Walkout Surveys, Construction Design, Permits, Financials & Payback, Approvals, Job Progress, Reporting, Forecasting, Invoicing, Quality Control, As Built Reconciliation, & Closing Jobs\n",
    "\n",
    "\n",
    "- The prototype has gone live and they are working on additional enhancements being released through the year, and this has been picked up by additional groups within Comcast.\n",
    "\n",
    "\n",
    "- This group, called the Next Generation Access Network, is essentially a startup in a major corporation- they are result driven and are working to stabilize the platform.\n",
    "\n",
    " \n",
    "### 5. Notes from the Manager\n",
    "\n",
    "- There are 6 openings- They are all very similar with slight variations and skillsets- looking for someone with SQL skills for data manipulation for all six roles.\n",
    "    - Four of these roles will be more on the data visualization and data analysis side of the platform. These positions will report to Ramya.\n",
    "    - The other two roles will report to Maher and they will be more geared towards Machine Learning.\n",
    "    \n",
    "    \n",
    "- Not just theoretical experience; the candidate needs to know ins and outs and have extensively used it.\n",
    "\n",
    "\n",
    "- SQL- very important!\n",
    "\n",
    "\n",
    "- Programming experience- if you have 1 language- this isn’t that hard and don’t need UDF’s but should be able to write queries to join 2 data sources\n",
    "\n",
    "\n",
    "- Any visualization tools- built reports/charts using R/Python- analytical tools experience\n",
    "\n",
    "\n",
    "- Classified as data scientist- realm of big data where they go and deal with unstructured data to make sense of it- analyze data (wrangle and manipulate)- build\n",
    "\n",
    "\n",
    "- Junior candidates are okay- need to have used the skillsets and willingness to learn\n",
    "\n",
    "### 6. Selling points:\n",
    "\n",
    "- They are using the AWS platform; they are heavy on using AWS stack- that is where all data is. They are also leveraging a lot of big data technologies such as Spark and Databricks. None of these are required for the position. Think of this as a great opportunity to learn and expand your hands on experience with cutting edge technology.\n",
    "\n",
    "\n",
    "- The work that is performed will have a huge impact on the customer. The problems that you will help solve impact over 25 million Comcast customers.\n",
    "\n",
    "\n",
    "- Team they are part of is different talents- what is confusing is that they don’t understand. Team is supportive and there are hardcore data scientists and engineers. Left alone to figure things out. Very collaborative\n",
    "\n",
    "\n",
    "- NGAN builds technology that other networking companies have not had the chance to do. They are trailblazers in the industry. Very few companies are working with data at this scale.\n",
    "\n",
    "### 7. Day to Day Responsibilities\n",
    "\n",
    "- Building a strong intuitive understanding of the problem domain (Next Generation Access Networks) and identifying testable hypotheses to explain interesting phenomena in this domain. \n",
    "\n",
    "\n",
    "- Selecting and transforming features and building & optimizing classifiers using machine learning techniques. \n",
    "\n",
    "\n",
    "- Integrating data from multiple sources including third party sources. \n",
    "\n",
    "\n",
    "- Data mining using state-of-the-art methods. \n",
    "\n",
    "\n",
    "- Enhancing data collection procedures to include information that is relevant for building analytic systems. \n",
    "\n",
    "\n",
    "- Frequent meeting/communication with stakeholders to interpret their needs, plan/organize, and discusses progress and results. \n",
    "\n",
    "\n",
    "- Developing actionable quantitative models in the areas of effectiveness, ROI, pricing and optimization. \n",
    "\n",
    "\n",
    "- Doing extensive data exploration and ad-hoc analysis and presenting insight in a clear manner. \n",
    "\n",
    "\n",
    "- Developing and communicating goals, strategies, tactics, project plans, timelines, and key performance metrics to reach goals.\n",
    " \n",
    "### 8. Overall Review of Required Skills Sets\n",
    "\n",
    "- 2+ years’ experience in an analytical role. Highly proficient using analytical tools, including strong SQL (Masters level experience is fine)\n",
    "\n",
    "\n",
    "- Experience in data visualization tools like looker, quick sight, tableau, etc.\n",
    "\n",
    "\n",
    "- Breadth of skills and experience in using diverse types of data, diverse data sources, different types of learning models\n",
    "\n",
    "\n",
    "- Strongly proficient in at least one of the following skills: Python or R\n",
    "\n",
    "\n",
    "- Strong ability to analyze data and make sound conclusions from data sets and provide narrative on conclusions\n",
    "\n",
    "\n",
    "- Expertise in data modeling and concepts; excellent analytical, planning, prototyping, automation of analysis and visualizations.\n",
    "\n",
    "\n",
    "- Excellent written and verbal communication skills; ability to adeptly communicate and interact with technical and non-technical audiences; ability to present to various groups including Executives\n",
    "\n",
    "\n",
    "- Self-motivated with a driven curiosity of data and the value it brings to business decision making\n",
    "\n",
    "\n",
    "- Ability to multi-task with strong attention to detail "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARIZED VERSION of the Above Job Description\n",
    "\n",
    "### Job Description\n",
    "1. This position is for the Next Generation Access Networks (NGAN) team, which focuses on the infrastructure side of Comcast services (cables, permits, quality control, permits/approvals, etc.).\n",
    "\n",
    "\n",
    "2. The job is for a new team under NGAN that focuses on collecting relevant data from third-party sources and making sense of it.\n",
    "    - This can be construed as a \"workflow orchestration tool\" to help minimize costs and optimize workflow.\n",
    "    - This team is currently in the process of \"stabilizing the platform\" and making it more useful and comprehensive.\n",
    "\n",
    "\n",
    "3. The team places a premium on curiosity and willingness to learn, making higher education a big plus in their book.\n",
    "    - Similarly, the team emphasizes real-world application of the relevant skillset - not just theoretical knowledge of what is needed for the position\n",
    "\n",
    "\n",
    "4. Day-to-day, data analysis/data science responsibilities are:\n",
    "    - Creating testable hypotheses to explain observed phenonema arising from the data.\n",
    "    - Collecting/wrangling, organizing, cleaning, and transforming data.\n",
    "    - Doing other _ad-hoc_ data analysis.\n",
    "    - Creating machine learning models, particularly classifiers.\n",
    "    - Developing quantitative models (ROI, pricing, etc.) to convey to stakeholders.\n",
    "\n",
    "### What I need to Study/Practice/Prepare For\n",
    "\n",
    "1. SQL, SQL, SQL!\n",
    "    - Need to show querying for basic joins\n",
    "    - Need to show how to load data from outside third-party data sources in SQL.\n",
    "    - Need to show ability to perform transformations/manipulations in SQL.\n",
    "    \n",
    "\n",
    "2. AWS Platform\n",
    "    - Need to learn AWS stack, including Spark _and_ Databricks.\n",
    "    - Need to establish familiarity with AWS platform, or at the absolute least, with \"a\" cloud platform.\n",
    "    \n",
    "  \n",
    "3. Know how to create models with either Python or R.\n",
    "\n",
    "\n",
    "4. Need to know \"a\" visualization tool, whether it be Tableau, Grafana, Quicksight, or Looker.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
